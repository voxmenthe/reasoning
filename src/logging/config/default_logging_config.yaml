version: 1
disable_existing_loggers: false

root:
  level: INFO
  handlers: [console]

loggers:
  logging.training:
    level: INFO
    handlers: [console, file, tensorboard]
    propagate: false
  
  logging.model:
    level: INFO
    handlers: [console, file, csv, tensorboard]
    propagate: false
    
  logging.reward:
    level: INFO
    handlers: [file, tensorboard]
    propagate: false
    
  logging.system:
    level: INFO
    handlers: [file]
    propagate: false
    
  logging.metrics:
    level: INFO
    handlers: [file, tensorboard]
    propagate: false

handlers:
  console:
    class: logging.StreamHandler
    formatter: standard
    level: INFO
    
  file:
    class: logging.handlers.RotatingFileHandler
    formatter: standard
    filename: logs/training.log
    maxBytes: 10485760  # 10MB
    backupCount: 5
    
  csv:
    class: logging.custom.CSVHandler
    filename: logs/model_outputs.csv
    columns: [timestamp, question, true_answer, model_answer, reasoning]
    buffer_size: 100
    flush_interval: 5.0
    
  tensorboard:
    class: logging.custom.TensorBoardHandler
    log_dir: logs/tensorboard
    flush_secs: 30
    max_queue: 100

formatters:
  standard:
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    datefmt: "%Y-%m-%d %H:%M:%S"
    
  json:
    format: json
    fields: [timestamp, level, name, message]

# Model evaluation metrics configuration
metrics:
  # How frequently to log metrics (in training steps)
  logging_frequency: 50
  
  # How frequently to run validation (in training steps)
  validation_frequency: 250
  
  # Sample a subset of batches for more expensive metrics
  sampling_ratio: 0.1
  
  # Enable/disable specific metric categories
  enable:
    reward_metrics: true
    generation_metrics: true
    validation_metrics: true
    resource_metrics: true
    
  # Validation dataset settings
  validation:
    dataset_path: "data/validation_set.json"
    max_samples: 100
    timeout_per_sample: 5  # seconds 